#!/usr/bin/env perl
#vim: et:ts=2:sw=2

# krakenhll-download.pl - based on centrifuge-download
# (c) Florian Breitwieser, 2017
# licensed under GPL-3

use strict;
use warnings;
use File::Basename;
use File::Fetch;
use File::Copy;
use File::Path qw/make_path remove_tree/;
use IO::Uncompress::Gunzip qw/gunzip $GunzipError/;
use autodie;
use Term::ANSIColor;
use Getopt::Long;
use LWP::UserAgent;


sub download_taxonomy(@);
sub download_contaminats(@);
sub download(@);
sub print_header_lines(@);
sub print_header_line_ac(@);
sub download_domain(@);
sub download_viral_neighbors(@);
sub download_viral_neighbors_url(@);
sub download_viral_neighbors2(@);

my $FTP="ftp://ftp.ncbi.nih.gov";
my @ALL_GENOMES=qw/bacteria viral archaea fungi protozoa invertebrate plant vertebrate_mammalian vertebrate_other/;
my @ALL_DATABASES=qw/refseq genbank taxonomy contaminants/;
my @ALL_ASSEMBLY_LEVELS=qw/Complete\ Genome Chromosome Scaffold Contig/;
my @SMALL_GENOMES=qw/mitochondrion plaasmid plastid/;

my %taxonomy;
my %taxonomy_map;

## Option parsing
my $DATABASE="refseq";
my $ASSEMBLY_LEVEL="Complete Genome";
my $REFSEQ_CATEGORY;
my $TAXID;

my $BASE_DIR;
my $DB_DIR;
my $N_PROC=5;
my $CHANGE_HEADER=0;
my $DO_DUST=0;
my $FILTER_UNPLACED=0;
my $VERBOSE=0;
my $OVERWRITE_FILES=0;
my $INCLUDE_VIRAL_NEIGHBORS=0;
my $DOMAINS;
my $DL_MOD_RSYNC;

my $SEQID_MAP_FILE;
my $TAXDB_FILE;
my $ADD_TAXID_FOR_GENOMES=0;
my $ADD_TAXID_FOR_SEQUENCES=0;
my $START_TAXID=1000000000;
my $NO_SEQ_TAXID;

my $n_children = 0;
my @pids;
my %taxid_name_map;

my $downloaded_viral_refseq=0;
my $FNA_FILES="genomic";

my $USAGE="\n".basename($0).
" [<options>] <pattern> <pattern>*

ARGUMENT
 <pattern>  Possible patterns:
              'contaminants'   downloads contaminant sequences from UniVec and EmVec
              'taxonomy'       downloads the NCBI taxonomy mappings
              'genbank'        downloads GenBank genomes (see parameters -a and -d)
              'refseq'         downloads RefSeq genomes (see parameters -a and -d)
              'refseq/DOMAIN'  downloads RefSeq genomes of DOMAIN (e.g. 'refseq/bacteria')
              'refseq/DOMAIN/ASS_LEVEL'    specifiy assembly level (e.g. 'refseq/fungi/Chromosome' or 'refseq/viral/Any')
              'refseq/DOMAIN/ASS_LEVEL/taxidTAXID'   specifify taxid (e.g. 'refseq/vertebrate_mammalian/taxid9606')

              
  By default, 'refseq' and 'genbank' download the domains and assembly levels specied
  with other parameters, however
                   - refseq and genbank can be proceeded by '/DOMAIN' or '/DOMAIN/ASS_LEVEL', e.g.
                     - refseq/archaea, refseq/viral/Any, or genbank/bacteria
                     - if ASS_LEVEL is not given, the default is used

COMMON OPTIONS
 -o <directory>     Folder to which the files are downloaded. Default: '.'
 --db <directory>   Alternative to -o: Download to <directory>/{library,taxonomy}.
 --threads <# of threads>  Number of processes when downloading (uses xargs). Default: '$N_PROC'
 --rsync, -R        Download using rsync.
 --overwrite        Redownload and overwrite files with the same name.
 -v                 Verbose.

WHEN USING database refseq OR genbank:
 -d <domain>        What domain to download. One or more of @ALL_GENOMES (comma separated).
 -a <assembly level>  Only download genomes with the specified assembly level. Default: '$ASSEMBLY_LEVEL'. Use 'Any' for any assembly level.
 -c <refseq category>   Only download genomes in the specified refseq category. Default: any.
 -t <taxids>        Only download the specified taxonomy IDs, comma separated. Default: any.
 --fna <seq types>  Comma-separated list of sequence types, including genomic, rna, rna_from_genomic, cds_from_genomic. Default: $FNA_FILES.
                    See the assembly project FTP site for available sequences
 -u                 Filter unplaced sequences.
 --dust, -D         Mask low-complexity regions using dustmasker.
 -l                 Modify sequence header to include taxonomy ID for Kraken (i.e. add '>kraken:taxid|TAXID' to each sequence).
 --include-viral-neighbors  Include neighbors for viral genomes as defined at https://www.ncbi.nlm.nih.gov/genome/viruses/.
                            Only works if refseq viral is downloaded in the same session!
";

# arguments: $OPTFIND (current index), $OPTARG (argument for option), $OPTERR (bash-specific)
Getopt::Long::Configure('no_auto_abbrev','pass_through');
GetOptions(
  "output|o=s"  =>\$BASE_DIR,
  "db=s" => \$DB_DIR,
  "threads|P=i" =>\$N_PROC,
  "domain|d=s"  => \$DOMAINS,
  "assembly-level|a=s" => \$ASSEMBLY_LEVEL,
  "category|c=s" => \$REFSEQ_CATEGORY,
  "taxonomy-id|t=s" => \$TAXID,
  "fna=s" => \$FNA_FILES,

  "taxonomy-file=s" => \$TAXDB_FILE,
  "seqid-map=s" => \$SEQID_MAP_FILE,
  "taxids-for-genomes" => \$ADD_TAXID_FOR_GENOMES,
  "taxids-for-sequences" => \$ADD_TAXID_FOR_SEQUENCES,
  "start-taxid=i" => \$START_TAXID,
  "no-sequence-taxids=s" => \$NO_SEQ_TAXID,

  "rsync|R" => \$DL_MOD_RSYNC,
  "include-viral-neighbors" => \$INCLUDE_VIRAL_NEIGHBORS,
  "filter-unplaced|u" => \$FILTER_UNPLACED,
  "dust|D" => \$DO_DUST,
  "change-header|l" => \$CHANGE_HEADER,
  "force" => \$OVERWRITE_FILES,
  "verbose|v" => \$VERBOSE) or die "Error in command line arguments";

if (!defined $ARGV[0] || !$ARGV[0] =~ /refseq|genbank|taxonomy|contaminants/) {
  print STDERR $USAGE;
  exit 1;
}

if (defined $BASE_DIR && defined $DB_DIR) {
  print "Define either --db or -o, not both!";
  exit 1;
}

if (defined $ADD_TAXID_FOR_GENOMES || defined $ADD_TAXID_FOR_SEQUENCES) {
  die "Specify a seqid map file with --seqid-map when adding taxonomy IDs!" unless defined $SEQID_MAP_FILE;
  die "Specify a taxonomy file with --taxonomy-file when adding taxonomy IDs!" unless defined $TAXDB_FILE;
}

my $SEQID_MAP;
if (defined $SEQID_MAP_FILE) {
  die "$SEQID_MAP_FILE already exists - please delete before continuing" if -s $SEQID_MAP_FILE;
  open($SEQID_MAP, ">", $SEQID_MAP_FILE) or die $!;
}

my $TAXDB;
if (defined $TAXDB_FILE) {
  die "$TAXDB_FILE already exists - please delete before continuing" if -s $TAXDB_FILE;
  open($TAXDB, ">", $TAXDB_FILE) or die $!;
}

my %skip_seq_taxids;
if (defined $NO_SEQ_TAXID) {
  foreach (split(/,/, $NO_SEQ_TAXID)) {
    $skip_seq_taxids{$_} = 1;
  }
}

my $ua = LWP::UserAgent->new( ssl_opts => { verify_hostname => 0 } );

# Use current directory as base directory
$BASE_DIR = "." unless defined $DB_DIR || defined $BASE_DIR;

# If DB directory is defined, use that as base directory
#  -- kept -o and --db options to allow the use of either Kraken and Centrifuge type command line
my $add_dir = defined $DB_DIR;
$BASE_DIR = $DB_DIR if defined $DB_DIR;
sub get_dir {
  my ($dir, $name) = @_;
  my $dir1 = $add_dir? "$dir/$name" : $dir;
  make_path $dir1;
  return $dir1;
}

my %select_taxonomy_ids;
if (defined $TAXID) {
  %select_taxonomy_ids = map { $_ => 1 } split(/,/, $TAXID);
}

if (!defined $ARGV[0]) {
  print STDERR $USAGE;
  exit 1;
}

foreach my $DATABASE (@ARGV) {
  if ( $DATABASE eq "taxonomy" ) { 
    download_taxonomy(get_dir($BASE_DIR,"taxonomy"));
  } elsif ( $DATABASE eq "contaminants" ) { 
    download_contaminats(get_dir($BASE_DIR,"library/contaminants"));
  } elsif ( $DATABASE =~ /^refseq/ || $DATABASE =~ /^genbank/ ) {
    my ($db, $domain, @levels) = split(/\//, $DATABASE);
    if (!defined $domain) {
      foreach my $domain (split(/,/,$DOMAINS)) {
        my $lib_dir = $add_dir? "$BASE_DIR/library/$domain" : "$BASE_DIR/$domain";
        download_domain($db, $lib_dir, $domain, $ASSEMBLY_LEVEL);
      }
    } else {
      my $lib_dir = $add_dir? "$BASE_DIR/library/$domain" : "$BASE_DIR/$domain";
      my $level = $ASSEMBLY_LEVEL;
      my $taxid = $TAXID;
      foreach (@levels) {
        if (/taxid(.*)/) {
          $taxid = $1;
        } else {
          $level = $_;
        }
      }
      download_domain($db, $lib_dir, $domain, $level, $taxid);
    }
  } else {
    print STDERR "Unknown database $DATABASE. \n";
    print STDERR $USAGE;
    exit 1;
  }
}

if ($INCLUDE_VIRAL_NEIGHBORS) {
  my $nbr_lib_dir = $add_dir? "$BASE_DIR/library/viral/Neighbors" : "$BASE_DIR/viral/Neighbors";
  download_viral_neighbors_url($nbr_lib_dir);
}


if (defined $SEQID_MAP_FILE) {
  close($SEQID_MAP);
}

if (defined $TAXDB_FILE) {
  close($TAXDB);
}

#########################################################
## Functions

sub download(@) {
  my ($url, $file, $gunzipped_filename) = @_;
  if (!$OVERWRITE_FILES && (( defined $gunzipped_filename && -s $gunzipped_filename) || (!defined $gunzipped_filename && -s $file))) {
    print STDERR "Not fetching $url - file $file exists.\n" if $VERBOSE;
    return 1;
  }

  if ($url =~ /^http/) {
    print STDERR "Fetching $url to $file ..." if $VERBOSE;
    if (!-d dirname($file)) {
      make_path(dirname($file));
    }
    my $response = $ua->get($url, ':content_file' => $file);
    if (!$response->is_success) {
      print STDERR "\nFAIL: Error downloading $url!\n";
      print STDERR $response->status_line."\n";
    } else {
      print STDERR "SUCCESS\n" if $VERBOSE;
    }
  } else {
    if ( $DL_MOD_RSYNC && $url =~ /^ftp/ ) {
     $url =~ s/^ftp/rsync/;
    }
    print STDERR "Fetching $url to $file ..." if $VERBOSE;

    my $ff = File::Fetch->new(uri=>"$url");
    my $where = $ff->fetch(to=> dirname($file)) or die "$ff->error URL: $url";
    move($where, $file);

    if (defined $gunzipped_filename) {
      print STDERR " GUNZIPPING" if $VERBOSE;
      gunzip $file => $gunzipped_filename or die "gunzip failed: $GunzipError";
      unlink $file;
      $file = $gunzipped_filename;
    }
    print STDERR " SUCCESS\n" if $VERBOSE;
  }
  #my $where = $ff->fetch(to=> dirname($file)) or die "\n$ff->error for $url!";
  return -s $file;
}

sub start_fork() {
  my $pid;
  return 0 if $N_PROC <= 1;
  if ($n_children == $N_PROC) {
    $pid = wait();
    --$n_children;
  }
  if (defined($pid = fork())) {
    if ($pid) {
      ++$n_children;
      #print STDERR "Parent: forked child $pid\n";
      push @pids, $pid;
    } 
  } else {
    print STDERR "ERROR: Failed to fork\n";
  }
  return $pid;
}

sub wait_children() {
  foreach my $pid (@pids) {
    waitpid $pid, 0;
  }
  @pids = ();
  $n_children = 0;
}

sub end_fork() {
  exit() unless $N_PROC <= 1;
}

sub download_viral_neighbors2(@) {
  my ($nbr_dir) = @_;
  my $dir = get_dir($BASE_DIR,"taxonomy");
  print STDERR "reading names file ...\n";
  my $names_file = "$dir/names.dmp";
  open (my $n, "<", $names_file);
  while (<$n>) {
    my ($taxid, undef, $name, undef, $type) = split /\t|\t/;
    next unless $type eq "scientific name";
    $taxid_name_map{$taxid} = $name;
  }
  close($n);

  print STDERR "downloading nucl_gb.accession2taxid ...\n";
  my $url = "ftp://ftp.ncbi.nlm.nih.gov/pub/taxonomy/accession2taxid/nucl_gb.accession2taxid.gz";
  download($url, "$dir/nucl_gb.accession2taxid.gz");

  print STDERR "sorting mapping file ...\n";
  my $sort_cmd = system("sort --help | grep -q parallel") == 0? "sort --parallel $N_PROC" : "sort";
  print STDERR "sort cmd: $sort_cmd\n";
  system("gunzip -c $dir/nucl_gb.accession2taxid.gz | cut -f 2,3 | $sort_cmd > $dir/nucl_gb.accession2taxid.sorted") unless -s "$dir/nucl_gb.accession2taxid.sorted";

  if (!-f "$nbr_dir/all-nbrs.fa") {
  my $fmt="fasta";
  #my $term="viruses[organism]+not+cellular+organisms[orgn]+not+wgs[prop]+not+ac_000001:ac_999999[pacc]+not+gbdiv+syn[prop]+and+nuccore+genome+samespecies[filter]";
  #my $term="viruses[organism] not cellular organisms[orgn] not wgs[prop] not gbdiv syn[prop] and (srcdb_refseq[prop] or (nuccore genome samespecies[filter] and (complete[title]) not unverified[title]))"; #include refseq
  my $term="viruses[organism] not cellular organisms[orgn] not wgs[prop] not gbdiv syn[prop] and (nuccore genome samespecies[filter] and (complete[title]) not unverified[title])";
  $term =~ s/ /+/g;
  my $esearch_url="https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi";
  my $complete_url="$esearch_url?db=nuccore&usehistory=y&retmax=1&retmode=json&term=$term";
  ## todo: go through it 10,000 entries at a time
  download($complete_url, "esearch_neighbor_res.json");

  my $n_res=`grep -m1 '"count":' esearch_neighbor_res.json | sed -e 's/.*: "//' -e 's/",.*//;`;
  chomp $n_res;
  print STDERR "found $n_res verified viral neighbors with complete genomes. \n";
  my $url_params=`cat esearch_neighbor_res.json | grep -e 'querykey' -e 'webenv' | sed -e 's/^ *"querykey": "/query_key=/' -e 's/^ *"webenv": "/webenv=/' -e 's/",//' | paste -sd\\&`;
  chomp $url_params;
  die "error getting viral neighbors with url $complete_url" if (!defined $url_params || $url_params == "");
  my $retstart = 0;
  my $retmax = 10000;
  #my @all_fas = ();
  while ($retstart < $n_res) {
	  print STDERR "downloading sequences ".($retstart+1)." to ".min($n_res, $retstart+$retmax)." ...";
	  download("https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=nuccore&$url_params&rettype=fasta&retstart=$retstart&retmax=$retmax", "$nbr_dir/all-nbrs-$retstart.fa");
	  #push @all_fas, "$nbr_dir/all-nbrs-$retstart.fa";
	  $retstart += $retmax;
  }
  }
}


sub download_viral_neighbors_for_taxid(@) {
  my ($taxID, $result_file) = @_;

  return if -s $result_file;

  # Step 1: Initiate esearch to get JSON with WebEnv and QueryKey parameters
  my $esearch_url="https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi";
  my $term="txid$taxID [Organism] not wgs[prop] not gbdiv syn[prop] and (nuccore genome samespecies[filter] and complete[title] not unverified[title])";
  $term =~ s/ /+/g;
  my $complete_url="$esearch_url?db=nuccore&usehistory=y&retmax=1&retmode=json&term=$term";
  download($complete_url, "esearch_neighbor_res.txid$taxID.json");

  my $n_res=`grep -m1 '"count":' esearch_neighbor_res.json | sed -e 's/.*: "//' -e 's/",.*//;`;
  chomp $n_res;
  print STDERR "found $n_res verified viral neighbors for taxonomy $taxID with complete genomes. \n";
  return if (!defined $n_res || $n_res == 0);

  # Step 2: Download FASTAs, 10k at a time
  my $url_params=`cat esearch_neighbor_res.json | grep -e 'querykey' -e 'webenv' | sed -e 's/^ *"querykey": "/query_key=/' -e 's/^ *"webenv": "/webenv=/' -e 's/",//' | paste -sd\\&`;
  chomp $url_params;
  die "error getting viral neighbors with url $complete_url" if (!defined $url_params || $url_params == "");
  my $retstart = 0;
  my $retmax = 10000;
  my @all_fas = ();
  while ($retstart < $n_res) {
	  print STDERR "downloading sequences ".($retstart+1)." to ".min($n_res, $retstart+$retmax)." ...";
	  download("https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=nuccore&$url_params&rettype=fasta&retstart=$retstart&retmax=$retmax", "$result_file-retstart_$retstart");
	  push @all_fas, "$result_file-retstart_$retstart";
	  $retstart += $retmax;
  }
  `mv -v @all_fas $result_file`;
}

sub download_viral_neighbors_url(@) {
  my ($nbr_dir) = @_;

  print STDERR "Reading names file ...\n";
  my $dir = get_dir($BASE_DIR,"taxonomy");
  my $names_file = "$dir/names.dmp";
  if (!-f $names_file) {
    download_taxonomy($dir);
  }
  open (my $N, "<", $names_file);
  while (<$N>) {
    next unless /scientific name/;
    my ($taxid, $name) = split /\t\|\t/;
    $taxid_name_map{$taxid} = $name;
  }
  close($N);

  print STDERR "Downloading nucl_gb.accession2taxid ...\n";
  my $url = "ftp://ftp.ncbi.nlm.nih.gov/pub/taxonomy/accession2taxid/nucl_gb.accession2taxid.gz";
  download($url, "$dir/nucl_gb.accession2taxid.gz");

  my $sorted_map_f = "$dir/nucl_gb.accession2taxid.sorted";
  print STDERR "Sorting mapping file ...\n";
  my $sort_cmd = system("sort --help | grep -q parallel") == 0? "sort --parallel $N_PROC" : "sort";
  system("gunzip -c $dir/nucl_gb.accession2taxid.gz | cut -f 2,3 | $sort_cmd > $sorted_map_f") unless -s $sorted_map_f;

  print STDERR "Downloading viral neighbors into $nbr_dir ...\n";
  my $term="viruses[organism] not cellular organisms[orgn] not wgs[prop] not gbdiv syn[prop] and (nuccore genome samespecies[filter] and (complete[title]) not unverified[title])";
  $term =~ s/ /+/g;
  my $esearch_url="https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi";
  my $complete_url="$esearch_url?db=nuccore&usehistory=y&retmax=1&retmode=json&term=$term";
  my $esearch_file = "$nbr_dir/esearch_neighbor_res.json";
  download($complete_url, $esearch_file);

  my $n_res=`grep -m1 '"count":' $esearch_file | sed -e 's/.*: "//' -e 's/",.*//'`;
  chomp $n_res;
  print STDERR "found $n_res verified viral neighbors with complete genomes, starting download ...";
  return if (!defined $n_res || $n_res eq 0);

  # Step 2: Download FASTAs, 10k at a time
  my $url_params=`cat $esearch_file | grep -e 'querykey' -e 'webenv' | sed -e 's/^ *"querykey": "/query_key=/' -e 's/^ *"webenv": "/webenv=/' -e 's/",//' | paste -sd\\&`;
  chomp $url_params;
  die "error getting viral neighbors with url $complete_url" if (!defined $url_params || $url_params eq "");
  my $retstart = 0;
  my $retmax = 10000;
  my @all_fas = ();
  while ($retstart < $n_res) {
    print STDERR "\r  Downloading $retmax viral neighbor sequence starting with ".($retstart+1)."/$n_res ..." unless $VERBOSE;

    #start_fork() and next;
    download("https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=nuccore&$url_params&rettype=fasta&retstart=$retstart&retmax=$retmax", "$nbr_dir/retstart_$retstart.fa");

    my $FA_HANDLE;
    my $fa_handle_open = 0;
    open (my $F, "<", "$nbr_dir/retstart_$retstart.fa") or die "Couln't open downloaded file";
    while (my $line = <$F>) {
      next if $line eq "\n";
      if ($line =~ /^>/) {
        (my $nbr_ac = $line) =~ s/.//;
        $nbr_ac =~ s/ .*//;
        chomp $nbr_ac;
   
        my $taxid = `look $nbr_ac $sorted_map_f | cut -f 2`;
        chomp $taxid;

        if (!defined $taxid || !defined $taxid_name_map{$taxid}) {
          my $res = `curl -s "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=nuccore&id=$nbr_ac&rettype=fasta&retmode=xml" | head -n 12  | egrep '<TSeq_taxid>|<TSeq_orgname>'  | sed -e 's#</.*>##' -e 's#.*<.*>##' | paste -sd\$'\\t'`;
          chomp $res;
          ($taxid) = split /\t/, $res;
        }

        my $name = $taxid_name_map{$taxid};
        if (!defined $taxid || !defined $name) {
          print STDERR "\nNo mapping for viral neighbor $nbr_ac!\n";
          next;
        }
        (my $name1 = $name) =~ s/[^a-zA-Z0-9_]/_/g;
        $name1 =~ s/__/_/g;
        system("mkdir -p $nbr_dir/$name1-tax$taxid");
        if ($fa_handle_open) {
          close($FA_HANDLE);
        } else {
          $fa_handle_open = 1;
        }
        my $file = "$nbr_dir/$name1-tax$taxid/$nbr_ac.fna";
        open($FA_HANDLE, ">", $file) or die "Couln't open file";
        print_header_line_ac($file, $nbr_ac, $taxid);
      }
      print $FA_HANDLE $line;
      #end_fork();
    }
    close($F);
    $retstart += $retmax;
  }
  print STDERR "\n";
  wait_children();

#  $pm->wait_all_children();
}

sub download_viral_neighbors(@) {
  my ($nbr_dir) = @_;

  print STDERR "Reading names file ...\n";
  my $dir = get_dir($BASE_DIR,"taxonomy");
  my $names_file = "$dir/names.dmp";
  if (!-f $names_file) {
    download_taxonomy($dir);
  }
  open (my $N, "<", $names_file);
  while (<$N>) {
    next unless /scientific name/;
    my ($taxid, $name) = split /\t\|\t/;
    $taxid_name_map{$taxid} = $name;
  }
  close($N);

  print STDERR "Downloading nucl_gb.accession2taxid ...\n";
  my $url = "ftp://ftp.ncbi.nlm.nih.gov/pub/taxonomy/accession2taxid/nucl_gb.accession2taxid.gz";
  download($url, "$dir/nucl_gb.accession2taxid.gz");

  my $sorted_map_f = "$dir/nucl_gb.accession2taxid.sorted";
  print STDERR "Sorting mapping file ...\n";
  my $sort_cmd = system("sort --help | grep -q parallel") == 0? "sort --parallel $N_PROC" : "sort";
  system("gunzip -c $dir/nucl_gb.accession2taxid.gz | cut -f 2,3 | $sort_cmd > $sorted_map_f") unless -s $sorted_map_f;

  print STDERR "Downloading viral neighbors into $nbr_dir ...\n";
  my $url1 = "https://www.ncbi.nlm.nih.gov/genomes/GenomesGroup.cgi?taxid=10239&cmd=download2";
  my $nbr_file = "$nbr_dir/viral_neighbors-taxid10239.nbr";
  download($url1, $nbr_file);
  open(my $F, "<", $nbr_file);
  my @file = <$F>;
  close($F);

  my $i = 0;
  my $n_genomes = scalar @file;

  foreach (@file) {
    next if /^#/;
    ++$i;
    print STDERR "\r  Downloading viral neighbor sequence $i/$n_genomes ..." unless $VERBOSE;
#    my $pid = $pm->start and next;
    chomp;
    my ($rep_acs, $nbr_ac, undef, undef, $nname, $sname) = split /\t/;
    my $taxid = `look $nbr_ac $sorted_map_f | cut -f 2`;
    chomp $taxid;

    if (!defined $taxid || !defined $taxid_name_map{$taxid}) {
      my $res = `curl -s "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=nuccore&id=$nbr_ac&rettype=fasta&retmode=xml" | head -n 12  | egrep '<TSeq_taxid>|<TSeq_orgname>'  | sed -e 's#</.*>##' -e 's#.*<.*>##' | paste -sd\$'\\t'`;
      chomp $res;
      ($taxid) = split /\t/, $res;
    }

    my $name = $taxid_name_map{$taxid};
    if (!defined $taxid || !defined $name) {
       print STDERR "\nNo mapping for viral neighbor $nbr_ac [rep: $rep_acs, $nname, $taxid]!\n";
       next;
    }
    (my $name1 = $name) =~ s/[^a-zA-Z0-9_]/_/g;
    $name1 =~ s/__/_/g;
    my $file = "$nbr_dir/$name1-tax$taxid/$nbr_ac.fna";
    system("mkdir -p $nbr_dir/$name1-tax$taxid");
    if (-s "$nbr_dir/$nbr_ac.fna") {
      system("mv -v $nbr_dir/$nbr_ac.fna $nbr_dir/$name1-tax$taxid/$nbr_ac.fna");
    }
    my $url = "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi?db=nucleotide&rettype=fasta&retmode=text&id=$nbr_ac";
    start_fork() && next;
    download($url,$file);
    end_fork();
    print_header_lines($file, $taxid, "$nname neighbors");
  }
  print STDERR "\n";
  wait_children();

#  $pm->wait_all_children();
}

sub add_taxid {
  my ($taxid, $genome_name, $sequence_name) = @_;
  my $skip_seq = defined $skip_seq_taxids{$taxid}; 

  if ($ADD_TAXID_FOR_GENOMES) {
    my $new_taxid = $START_TAXID++;
    print $TAXDB $new_taxid,"\t",$taxid,"\tgenome\t",$genome_name,"\n";
    $taxid = $new_taxid;
  }

  if ($ADD_TAXID_FOR_SEQUENCES && !$skip_seq) {
    my $new_taxid = $START_TAXID++;
    print $TAXDB $new_taxid,"\t",$taxid,"\tsequence\t",$sequence_name,"\n";
  }
  return $taxid;
}

sub print_header_lines(@) {
  my ($file, $taxid, $name) = @_;
  return unless -f $file;
  next unless $SEQID_MAP_FILE;
  print STDERR "Making map file for $file\n" if ($VERBOSE);

  open (my $G, "<", $file);
  while (<$G>) {
    next unless /^>(([^ ]*).*)/;
    #$taxid = "$taxid\t$name" if defined $name;
    $taxid = add_taxid($taxid, $name, $1);
    print $SEQID_MAP "$2\t$taxid\n";
  }
  close($G);
}

sub print_header_line_ac(@) {
  my ($ac, $taxid, $name) = @_;
  next unless $SEQID_MAP_FILE;
  $taxid = add_taxid($taxid, $name, $1);
  #$taxid = "$taxid\t$name" if defined $name;
  print $SEQID_MAP "$ac\t$taxid\n";
}


sub download_contaminats(@) {
  my ($CONTAMINANT_DIR) = @_;
  print STDERR "Downloading contaminant databases ... \n";
  my $CONTAMINANT_TAXID=32630;
  make_path $CONTAMINANT_DIR;

  # download UniVec and EmVec database
  download("ftp://ftp.ncbi.nlm.nih.gov/pub/UniVec/UniVec","$CONTAMINANT_DIR/UniVec.fna");
  download("ftp://ftp.ebi.ac.uk/pub/databases/emvec/emvec.dat.gz","$CONTAMINANT_DIR/emvec.dat.gz", "$CONTAMINANT_DIR/emvec.dat");

  open(my $E1, "<", "$CONTAMINANT_DIR/emvec.dat");
  open(my $E2, ">", "$CONTAMINANT_DIR/EmVec.fna");

  my ($ac,$de);
  my $in_seq = 0;
  while(<$E1>) {
    if (/^AC\s+(.*)/) {
      $ac = $1;
      $ac =~ s/;$//;
    } elsif (/^DE\s+(.*)/) {
      $de = $1;
   } elsif (/^SQ/) {
      $in_seq = 1;
      print $E2 ">$ac $de\n";
    } elsif ($in_seq) {
      if (/^\s+[agct]/) {
        s/\s+[0-9]+$//;
       s/ //g;
       print $E2 $_;
      } else {
        $in_seq = 0;
      }
    }
  }
  close($E2);
  close($E1);
  unlink("$CONTAMINANT_DIR/emvec.dat");
 
  if ( $CHANGE_HEADER ) {
    system("sed -i 's/^>/>taxid|$CONTAMINANT_TAXID /' $CONTAMINANT_DIR/UniVec.fna");
    system("sed -i 's/^>/>taxid|$CONTAMINANT_TAXID /' $CONTAMINANT_DIR/EmVec.fna");
  } else {
    print_header_lines("$CONTAMINANT_DIR/UniVec.fna", $CONTAMINANT_TAXID, "UniVec");
    print_header_lines("$CONTAMINANT_DIR/EmVec.fna", $CONTAMINANT_TAXID, "EmVec");
  }
}

sub download_taxonomy(@) {
  my ($dir) = @_;
  print STDERR "Downloading NCBI taxonomy ... \n";
  make_path $dir;

  download("$FTP/pub/taxonomy/taxdump.tar.gz", "$dir/taxdump.tar.gz");
  system("tar -C $dir -zxvf $dir/taxdump.tar.gz nodes.dmp names.dmp 1>&2");
  system("date > $dir/timestamp");
}

sub download_domain(@) {
  my ($DATABASE, $domain_dir, $domain, $_assembly_level, $_taxid) = @_;
  $_assembly_level =~ s/ /_/g;
  print STDERR "Downloading assembly summary file for $domain genomes, and filtering to assembly level $_assembly_level";
  print STDERR (defined $_taxid? " with taxid $_taxid.\n" : ".\n");
  die unless defined $domain_dir && defined $domain;
  if (-d $domain_dir) {
    print STDERR "WARNING: $domain_dir already exists - potentially overwriting files.\n";
  } else {
    make_path $domain_dir;
  }
  my $ass_file = "$domain_dir/assembly_summary.txt";
  my $ass_file_filtered = "$domain_dir/assembly_summary_filtered.txt";
  my $n_genomes = 0;
  download("ftp://ftp.ncbi.nlm.nih.gov/genomes/$DATABASE/$domain/assembly_summary.txt", $ass_file) or die "Could not download assembly summary file!";

  my $is_viral_refseq =1 if $domain eq "viral" && $DATABASE eq "refseq";

  my @genomes_to_dl;
  open(my $A1, "<", $ass_file);
  open(my $A2, ">", $ass_file_filtered);
  while (<$A1>) {
    next if /^#/;
    my ($assembly_accession, $bioproject, $biosample, $wgs_master, $refseq_category, 
      $taxid, $species_taxid, $organism_name, $infraspecific_name, $isolate, $version_status, 
      $assembly_level, $release_type, $genome_rep, $seq_rel_date, $asm_name, $submitter, 
      $gbrs_paired_asm, $paired_asm_comp, $ftp_path, $excluded_from_refseq, $relation_to_type_material) = split /\t/;

	$assembly_level =~ s/ /_/g;
    next unless $version_status eq "latest";
    next if ($_assembly_level ne "Any" && $assembly_level ne $_assembly_level);
    next if (defined $REFSEQ_CATEGORY && $refseq_category ne $REFSEQ_CATEGORY);
    next if (defined $_taxid && $taxid ne $_taxid);
    print $A2 $_;
    ++ $n_genomes;
    push @genomes_to_dl, [$ftp_path, $taxid, $organism_name, $infraspecific_name, $assembly_accession, $assembly_level];
  }
  close $A2;
  close $A1;

  my $downloaded_files = 0;
  my $existing_files = 0;

  my $i = 0;
  foreach my $g (@genomes_to_dl) {
    my ($ftp_path, $taxid, $organism_name, $infraspecific_name, $assembly_accession, $assembly_level) = @$g;
    ++$i;
    #print STDERR "\r                                                                               " unless $VERBOSE;
    print STDERR "\r Downloading $domain genomes:  $i/$n_genomes ... " unless $VERBOSE;

    if (defined $infraspecific_name) {
        (my $i1 = $infraspecific_name) =~ s/strain=//;
        $organism_name .= " $infraspecific_name" unless $organism_name =~ /\Q$i1\E/ || $i1 eq "";
    }


    my $bname = basename($ftp_path);
    ( my $organism_name1 = $organism_name ) =~ s/[^a-zA-Z0-9_]/_/g;
    $organism_name1 = substr($organism_name1, 0, 100);
    $organism_name1 =~ s/__/_/g;
    $organism_name1 =~ s/_$//;
    my $bname1 = "${organism_name1}-tax${taxid}-${bname}";
    
    $assembly_level =~ s/ /_/g;
    my $download_dir = "$domain_dir/$assembly_level";
    my $nbr_download_dir = "$domain_dir/Neighbors";
    foreach my $ext (split(/,/, $FNA_FILES)) {
      my $full_ftp_path = "$ftp_path/${bname}_${ext}.fna.gz";
      my $bfname = $bname1."_".$ext;
      my $nbr_fname = $bfname."-neighbors.fna";
      my $fname = $bfname.".fna";
      my $fullfname1 = $DO_DUST? "$download_dir/${bfname}_dustmasked.fna" : "$download_dir/$fname";

      if (!$OVERWRITE_FILES && -s $fullfname1) {
        print STDERR "$download_dir/$fname exists - not downloading.. \n" if $VERBOSE;
        ++$existing_files;
      } else {
        ++$downloaded_files;
        start_fork() && next;
        download($full_ftp_path, "$download_dir/$fname.gz", "$download_dir/$fname");
        end_fork();
      }

      if ($CHANGE_HEADER) {
        system("sed -i 's/^>/>kraken:taxid|$taxid /' '$download_dir/$fname'");
      }
      if ($FILTER_UNPLACED) {
        die("Not implemented");
      }

      if ($DO_DUST || !-s $fullfname1) {
        start_fork() && next;
        ## TODO: Consider hard-masking only low-complexity stretches with 10 or more bps
        system("dustmasker -infmt fasta -in '$download_dir/$fname' -level 20 -outfmt fasta | sed '/^>/! s/[^AGCT]/N/g' > '$fullfname1'");
        unlink("$download_dir/$fname");
        end_fork();
      }

      ## Output sequenceID to taxonomy ID map
      print_header_lines($fullfname1, $taxid, "$assembly_accession $organism_name");
    }
  }

  wait_children();

  print STDERR "  downloaded $downloaded_files files, $existing_files already existed.\n";
}
